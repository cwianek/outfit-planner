name: Lint and Test Charts

on:
  push:
    branches:
      - master
  pull_request:
  merge_group:

jobs:
  build-dashboard-frontend:
    uses: cwianek/outfit-planner/.github/workflows/dashboard-frontend-build.yml@master
    secrets: inherit

  build-products-frontend:
    uses: cwianek/outfit-planner/.github/workflows/products-frontend-build.yml@master
    secrets: inherit

  build-outfits-frontend:
    uses: cwianek/outfit-planner/.github/workflows/outfit-frontend-build.yml@master
    secrets: inherit

  build-keycloak-server:
    uses: cwianek/outfit-planner/.github/workflows/keycloak-server-build.yml@master
    secrets: inherit

  build-integration-tests:
    uses: cwianek/outfit-planner/.github/workflows/integration-tests.yml@master
    secrets: inherit

  build-outfit-service:
    uses: cwianek/outfit-planner/.github/workflows/outfit-service-build.yml@master
    secrets: inherit

  build-product-service:
    uses: cwianek/outfit-planner/.github/workflows/product-service-build.yml@master
    secrets: inherit

  build-prediction-service:
    uses: cwianek/outfit-planner/.github/workflows/prediction-service-build.yml@master
    secrets: inherit


  Test-on-cluster:
    needs:
      - build-dashboard-frontend
      - build-products-frontend
      - build-outfits-frontend
      - build-keycloak-server
      - build-integration-tests
      - build-outfit-service
      - build-product-service
      - build-prediction-service

    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      ## starts the cluster
      - name: Testing on a k8s Kind Cluster
        uses: helm/kind-action@v1.9.0

      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}

      - name: Install Helmfile
        run: |
          wget https://github.com/helmfile/helmfile/releases/download/v0.161.0/helmfile_0.161.0_linux_amd64.tar.gz -O /tmp/helmfile.tar.gz
          tar -xzf /tmp/helmfile.tar.gz -C /usr/local/bin/
          chmod +x /usr/local/bin/helmfile

      - name: Install helm-diff plugin
        run: |
          helm plugin install https://github.com/databus23/helm-diff

      ## makes sure cluster is up and running
      - run: |
          kubectl cluster-info
          kubectl get nodes

      - name : Preparing cluster for kube-ez
        run: |
          cd $GITHUB_WORKSPACE/outfit-planner-system/infrastructure/kubernetes
          helmfile --file helmfile.yaml  apply
        env:
          ENV_COMMIT_SHA: ${{ github.ref == 'refs/heads/master' && 'latest' || github.sha }}


      - name: Wait for Pods to be Running
        run: |
          timeout=360
          interval=30
          elapsed=0
          
          while [[ $elapsed -lt $timeout ]]; do
            echo "Waiting for pods to be ready. Elapsed time: $elapsed seconds."
            kubectl get pods --all-namespaces
            kubectl get pods --all-namespaces -o=jsonpath='{range .items[*]}{.metadata.namespace}{"\t"}{.metadata.name}{"\t"}{.status.phase}{"\t"}{"\n"}{end}' | column -t
          
            # Check if there are still pods not in "Running" or "Completed" state
            not_ready_pods=$(kubectl get pods --field-selector=status.phase!=Running,status.phase!=Succeeded --all-namespaces | grep -v 'NAMESPACE' | wc -l)
            if [[ $not_ready_pods -eq 0 ]]; then
              echo "All pods are now in 'Running' or 'Completed' state. Exiting loop."
              break
            fi
          
            sleep $interval
            elapsed=$((elapsed + interval))
          done
          
          # Get and describe pods with errors
          error_pods=$(kubectl get pods --field-selector=status.phase!=Running,status.phase!=Succeeded --all-namespaces | grep -v 'NAMESPACE' | awk '{print $2}')
          if [[ $error_pods -gt 0 ]]; then    
            for pod in $error_pods; do
              echo "Describing pod with errors: $pod \n\n"
              kubectl describe pod $pod --namespace=$(kubectl get pod $pod -o=jsonpath='{.metadata.namespace}')
            done
          
           echo "Error: Some pods are not in 'Running' or 'Completed' state after the timeout. Exiting with an error."
           exit 1
          fi

      - name: Check tests status
        run: |
          
          INTEGRATION_TESTS_POD=$(kubectl get pods -l app=integration-tests -o jsonpath="{.items[0].metadata.name}" -n default)
          echo "[kek] Integration Tests Pod Name: $INTEGRATION_TESTS_POD"
          
          for _ in {1..30}; do
            if kubectl exec $INTEGRATION_TESTS_POD -- test -e /app/test_status.txt; then
              echo "test_status.txt found. Continuing..."
              break
            else
              echo "Waiting for test_status.txt to exist..."
              sleep 5
            fi
          done
          
          kubectl cp $INTEGRATION_TESTS_POD:/app/test_status.txt $GITHUB_WORKSPACE/test_status.txt

      - name: Print all logs
        if: always()
        run: |
          echo "All logs:"
          kubectl get pods --all-namespaces -o json | jq -r '.items[] | "kubectl logs -n \(.metadata.namespace) \(.metadata.name)"' | sh

      - name: Check tests status
        run: |
          TEST_STATUS=$(cat $GITHUB_WORKSPACE/test_status.txt)

          # Check the test status and exit with an error if it's a failure
          if [ "$TEST_STATUS" = "failure" ]; then
            echo "Integration tests failed. Exiting with an error."
            exit 1
          else
            echo "Integration tests passed. Continuing..."
          fi
